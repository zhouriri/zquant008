# Copyright 2025 ZQuant Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Author: kevin
# Contact:
#     - Email: kevin@vip.qq.com
#     - Wechat: zquant2025
#     - Issues: https://github.com/yoyoung/zquant/issues
#     - Documentation: https://github.com/yoyoung/zquant/blob/main/README.md
#     - Repository: https://github.com/yoyoung/zquant

"""
from typing import List, Optional

数据采集定时任务调度
"""

from datetime import date, datetime, timedelta

from loguru import logger
from sqlalchemy import inspect
from sqlalchemy.orm import Session

from zquant.data.etl.tushare import TushareClient
from zquant.data.storage import DataStorage
from zquant.data.storage_base import log_sql_statement
from zquant.database import Base, engine
from zquant.models.scheduler import TaskExecution
from zquant.scheduler.utils import update_execution_progress
from zquant.services.data import DataService


class DataScheduler:
    """数据采集调度器"""

    def __init__(self):
        self.tushare = TushareClient()
        self.storage = DataStorage()

    def _ensure_tables_exist(self, db: Session, table_names: list = None):
        """
        确保数据表存在，如果不存在则创建

        Args:
            db: 数据库会话
            table_names: 需要检查的表名列表，如果为None则检查所有数据相关表
        """
        try:
            from zquant.models.data import Fundamental, Tustock, TustockTradecal

            # 默认检查所有数据表
            if table_names is None:
                tables_to_check = [
                    Tustock.__table__,
                    Fundamental.__table__,
                    TustockTradecal.__table__,
                ]
            else:
                # 根据表名映射到对应的表对象
                table_map = {
                    Tustock.__tablename__: Tustock.__table__,
                    Fundamental.__tablename__: Fundamental.__table__,
                    TustockTradecal.__tablename__: TustockTradecal.__table__,
                }
                tables_to_check = [table_map[name] for name in table_names if name in table_map]

            # 检查表是否存在
            inspector = inspect(engine)
            existing_tables = inspector.get_table_names()

            tables_to_create = []
            for table in tables_to_check:
                if table.name not in existing_tables:
                    tables_to_create.append(table)
                    logger.info(f"表 {table.name} 不存在，将在同步前创建")

            # 创建不存在的表
            if tables_to_create:
                logger.info(f"正在创建 {len(tables_to_create)} 个数据表（包含字段注释）...")
                Base.metadata.create_all(bind=engine, tables=tables_to_create)
                logger.info(f"成功创建 {len(tables_to_create)} 个数据表")

                # 确保字段注释正确写入（针对 Tustock 表）
                for table in tables_to_create:
                    if table.name == Tustock.__tablename__:
                        self._ensure_column_comments(db, table.name, Tustock)
                        break
        except Exception as e:
            logger.error(f"检查/创建数据表失败: {e}")
            # 不抛出异常，让同步继续尝试，如果表真的不存在会在插入时报错
            raise

    def _ensure_column_comments(self, db: Session, table_name: str, model_class):
        """
        确保表的字段注释正确写入数据库
        如果 SQLAlchemy 创建表时注释未写入，则使用 ALTER TABLE 补充

        Args:
            db: 数据库会话
            table_name: 表名
            model_class: 模型类
        """
        try:
            from sqlalchemy import text

            from zquant.utils.model_utils import get_field_comments

            # 获取模型定义的注释
            expected_comments = get_field_comments(model_class)
            if not expected_comments:
                return

            # 查询数据库中的字段注释
            sql = """
                SELECT COLUMN_NAME, COLUMN_COMMENT
                FROM INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_SCHEMA = DATABASE()
                AND TABLE_NAME = :table_name
            """
            # 打印SQL语句
            log_sql_statement(sql, {"table_name": table_name})
            result = db.execute(text(sql), {"table_name": table_name})
            db_comments = {row[0]: row[1] for row in result}

            # 检查并补充缺失的注释
            missing_comments = []
            for field_name, expected_comment in expected_comments.items():
                db_comment = db_comments.get(field_name, "")
                if not db_comment or db_comment.strip() == "" or db_comment != expected_comment:
                    # 注释缺失或不一致，使用 ALTER TABLE 添加/更新
                    try:
                        column_def = self._get_column_definition(model_class, field_name)
                        if column_def:
                            # 构建 ALTER TABLE 语句
                            alter_sql = f"ALTER TABLE `{table_name}` MODIFY COLUMN `{field_name}` {column_def} COMMENT '{expected_comment}'"
                            # 打印SQL语句
                            log_sql_statement(alter_sql)
                            db.execute(text(alter_sql))
                            db.commit()
                            action = "已补充" if not db_comment or db_comment.strip() == "" else "已更新"
                            logger.info(f"已为表 {table_name} 的字段 {field_name} {action}注释: {expected_comment}")
                            missing_comments.append(f"{field_name} ({action})")
                    except Exception as e:
                        logger.warning(f"为表 {table_name} 的字段 {field_name} 添加/更新注释失败: {e}")
                        missing_comments.append(f"{field_name} (失败)")

            if missing_comments:
                logger.info(f"表 {table_name} 字段注释处理完成，处理了 {len(missing_comments)} 个字段")
            else:
                logger.debug(f"表 {table_name} 所有字段注释已正确")
        except Exception as e:
            logger.warning(f"确保表 {table_name} 字段注释时出错: {e}（不影响功能）")

    def _get_latest_trading_date(self, db: Session) -> date:
        """
        获取最后一个交易日

        Args:
            db: 数据库会话

        Returns:
            最后一个交易日，如果未找到则返回今天
        """
        try:
            from zquant.models.data import TustockTradecal
            from sqlalchemy import desc

            latest = (
                db.query(TustockTradecal.cal_date)
                .filter(TustockTradecal.is_open == 1, TustockTradecal.cal_date <= date.today())
                .order_by(desc(TustockTradecal.cal_date))
                .first()
            )

            if latest and latest[0]:
                return latest[0]
            # 如果未找到交易日，返回今天
            return date.today()
        except Exception as e:
            logger.warning(f"获取最近交易日失败: {e}，使用今天日期")
            return date.today()

    def _get_column_definition(self, model_class, field_name: str) -> str:
        """
        获取字段的完整定义（用于 ALTER TABLE）

        Args:
            model_class: 模型类
            field_name: 字段名

        Returns:
            字段定义字符串
        """
        from sqlalchemy import inspect as sqlalchemy_inspect

        from zquant.utils.db_type_utils import convert_sqlalchemy_type_to_mysql

        mapper = sqlalchemy_inspect(model_class)
        column = mapper.columns.get(field_name)
        if not column:
            return ""

        # 使用数据库工具函数转换类型
        mysql_type = convert_sqlalchemy_type_to_mysql(column.type)

        nullable = "NULL" if column.nullable else "NOT NULL"

        # 处理默认值
        default = ""
        if column.default is not None:
            if hasattr(column.default, "arg"):
                # 处理常量默认值
                default_val = column.default.arg
                if isinstance(default_val, str):
                    default = f"DEFAULT '{default_val}'"
                elif default_val is not None:
                    default = f"DEFAULT {default_val}"
            elif callable(column.default):
                # 处理函数默认值（如 func.now()）
                default_str = str(column.default)
                if "now" in default_str.lower() or "current_timestamp" in default_str.lower():
                    default = "DEFAULT CURRENT_TIMESTAMP"

        # 处理自增
        auto_increment = ""
        if column.autoincrement and column.primary_key:
            auto_increment = "AUTO_INCREMENT"

        # 组合列定义
        parts = [mysql_type, nullable]
        if default:
            parts.append(default)
        if auto_increment:
            parts.append(auto_increment)

        return " ".join(parts).strip()

    def sync_stock_list(self, db: Session, extra_info: Optional[dict] = None, execution: Optional[TaskExecution] = None) -> int:
        """
        同步股票列表

        Args:
            db: 数据库会话
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            # 确保表存在
            from zquant.models.data import Tustock

            self._ensure_tables_exist(db, [Tustock.__tablename__])

            logger.info("开始同步股票列表...")
            update_execution_progress(db, execution, message="正在从 Tushare 获取股票列表...")
            
            df = self.tushare.get_stock_list()
            
            update_execution_progress(db, execution, message=f"获取到 {len(df)} 只股票，正在写入数据库...")
            count = self.storage.upsert_stocks(db, df, extra_info)

            # 记录结束时间和结果
            end_time = datetime.now()
            table_name = Tustock.__tablename__
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stock_basic",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"股票列表同步完成，更新 {count} 条")
            update_execution_progress(db, execution, progress_percent=100, message=f"股票列表同步完成，更新 {count} 条")

            # ==================== 新增：分表自动管理 ====================
            # 检测新增股票代码并初始化分表
            try:
                from zquant.services.partition_manager import PartitionManager

                logger.info("检测新增股票代码...")
                update_execution_progress(db, execution, message="正在检测并初始化新增股票分表...")
                new_codes = PartitionManager.detect_new_stock_codes(db)

                if new_codes:
                    logger.info(f"发现 {len(new_codes)} 只新增股票，开始初始化分表...")
                    
                    # 为新增代码初始化所有类型的分表
                    init_result = PartitionManager.init_partition_tables_for_codes(db, new_codes)
                    logger.info(
                        f"分表初始化完成: 成功 {init_result['success']}/{init_result['total']}，"
                        f"失败 {len(init_result['failed'])}"
                    )

                    # 更新所有分表视图
                    logger.info("更新所有分表视图...")
                    view_result = PartitionManager.update_all_views(db)
                    success_views = sum(1 for v in view_result.values() if v)
                    logger.info(f"视图更新完成: {success_views}/{len(view_result)} 个视图更新成功")
                else:
                    logger.info("未检测到新增股票代码，跳过分表初始化")

            except Exception as partition_error:
                # 分表初始化失败不影响主流程
                logger.error(f"分表自动管理失败: {partition_error}")
                logger.warning("分表初始化失败不影响股票列表同步，可稍后手动初始化")
            # ==================== 分表自动管理结束 ====================

            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import Tustock

            table_name = Tustock.__tablename__
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stock_basic",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步股票列表失败: {e}")
            raise


    def sync_trading_calendar(
        self,
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        exchanges: List[str] | None = None,
        extra_info: Optional[dict] = None,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步交易日历

        Args:
            db: 数据库会话
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            exchanges: 交易所列表，如果为None则同步上交所和深交所
                SSE=上交所, SZSE=深交所
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            # 确保表存在
            from zquant.models.data import TustockTradecal

            self._ensure_tables_exist(db, [TustockTradecal.__tablename__])

            # 默认同步上交所和深交所
            if exchanges is None:
                exchanges = ["SSE", "SZSE"]

            logger.info(f"开始同步交易日历，交易所：{exchanges}")
            update_execution_progress(db, execution, message=f"开始同步交易日历: {exchanges}")
            
            if not start_date:
                start_date = (date.today() - timedelta(days=365)).strftime("%Y%m%d")
            if not end_date:
                end_date = (date.today() + timedelta(days=365)).strftime("%Y%m%d")

            total_count = 0
            for i, exchange in enumerate(exchanges, 1):
                try:
                    logger.info(f"同步 {exchange} 交易日历...")
                    update_execution_progress(
                        db, 
                        execution, 
                        processed_items=i-1, 
                        total_items=len(exchanges), 
                        current_item=exchange,
                        message=f"正在同步 {exchange} 交易日历 ({start_date} 至 {end_date})..."
                    )
                    
                    df = self.tushare.get_trade_cal(exchange=exchange, start_date=start_date, end_date=end_date)
                    count = self.storage.upsert_trading_calendar(db, df, extra_info)
                    total_count += count
                    logger.info(f"{exchange} 交易日历同步完成，更新 {count} 条")
                except Exception as e:
                    if "Task terminated" in str(e):
                        raise
                    logger.error(f"同步 {exchange} 交易日历失败: {e}")
                    # 继续同步其他交易所，不中断整个流程
                    continue

            # 记录结束时间和结果
            end_time = datetime.now()
            table_name = TustockTradecal.__tablename__
            operation_result = "success" if total_count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=total_count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="trade_cal",
                    api_data_count=total_count,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"交易日历同步完成，共更新 {total_count} 条")
            update_execution_progress(
                db, 
                execution, 
                processed_items=len(exchanges), 
                total_items=len(exchanges),
                message=f"交易日历同步完成，更新 {total_count} 条"
            )
            return total_count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import TustockTradecal

            table_name = TustockTradecal.__tablename__
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="trade_cal",
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步交易日历失败: {e}")
            raise

    def sync_daily_data(
        self,
        db: Session,
        ts_code: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        update_view: bool = True,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步单只股票的日线数据（按 ts_code 分表存储）

        Args:
            db: 数据库会话
            ts_code: TS代码，如：000001.SZ
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            update_view: 是否更新视图，默认True。批量同步时建议设置为False，完成后统一更新
            execution: 执行记录对象（可选）
        """
        try:
            # 确保基础表存在
            from zquant.models.data import Tustock

            self._ensure_tables_exist(db, [Tustock.__tablename__])

            logger.info(f"开始同步 {ts_code} 日线数据...")
            update_execution_progress(db, execution, message=f"正在同步 {ts_code} 日线数据...")
            
            if not start_date:
                # 默认获取最近一年的数据
                start_date = (date.today() - timedelta(days=365)).strftime("%Y%m%d")
            if not end_date:
                end_date = date.today().strftime("%Y%m%d")

            # 获取前复权数据
            df = self.tushare.get_daily_data(ts_code, start_date, end_date, adj="qfq")
            if df.empty:
                logger.warning(f"{ts_code} 无数据")
                update_execution_progress(db, execution, message=f"{ts_code} 无数据")
                return 0

            # 记录开始时间
            start_time = datetime.now()

            # 使用新的分表存储方法
            count = self.storage.upsert_daily_data(db, df, ts_code, extra_info, update_view)

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import get_daily_table_name

            table_name = get_daily_table_name(ts_code)
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"{ts_code} 日线数据同步完成，更新 {count} 条")
            update_execution_progress(db, execution, message=f"{ts_code} 同步完成，更新 {count} 条")
            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import get_daily_table_name

            table_name = get_daily_table_name(ts_code)
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步 {ts_code} 日线数据失败: {e}")
            raise

    def sync_all_daily_data(
        self,
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        codelist: List[str] | None = None,
        execution: Optional[TaskExecution] = None,
    ) -> dict:
        """
        同步所有股票的日线数据（增量更新）

        Args:
            db: 数据库会话
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            codelist: TS代码列表（可选），如果提供则只同步列表中的股票
            execution: 执行记录对象（可选）

        同步策略：
            - 规则一（所有参数均未传入，start_date == end_date，且不传 codelist）：
              使用批量API（get_all_daily_data_by_date）一次获取所有股票数据
            - 规则二（至少有一个参数传入，或 start_date != end_date，或传入了 codelist）：
              循环调用API（get_daily_data）获取每个股票数据
        """
        start_time = datetime.now()
        try:
            logger.info("开始同步所有股票日线数据...")
            update_execution_progress(db, execution, message="正在准备同步...")
            from zquant.models.data import Tustock

            # 确保基础表存在
            self._ensure_tables_exist(db, [Tustock.__tablename__])

            # 判断是否为按天同步（开始日期和结束日期相同）
            # 规则一：所有参数均未传入时，start_date == end_date（都是最后一个交易日）
            # 规则二：至少有一个参数传入时，如果只传日期且 start_date == end_date，也使用批量API
            is_single_day = start_date and end_date and start_date == end_date

            if is_single_day:
                # 规则一/按天同步：调用一次 API 获取所有股票数据，然后批量写入
                logger.info(f"批量API同步模式（按天）：{start_date}")
                update_execution_progress(db, execution, message=f"正在通过批量API获取数据: {start_date}")
                if codelist:
                    logger.info(f"指定股票列表，共 {len(codelist)} 只股票，将从批量数据中过滤")
                try:
                    # 调用批量 API 获取所有股票数据
                    all_data_df = self.tushare.get_all_daily_data_by_date(start_date, adj="qfq")

                    if all_data_df.empty:
                        logger.warning(f"{start_date} 无数据")
                        return {"total": 0, "success": 0, "failed": []}

                    # 如果提供了 codelist，过滤数据
                    if codelist:
                        before_count = len(all_data_df)
                        all_data_df = all_data_df[all_data_df["ts_code"].isin(codelist)]
                        after_count = len(all_data_df)
                        logger.info(f"根据股票列表过滤：{before_count} -> {after_count} 条数据")
                        if all_data_df.empty:
                            logger.warning(f"{start_date} 在指定股票列表中无数据")
                            return {"total": len(codelist), "success": 0, "failed": codelist}

                    logger.info(f"获取到 {len(all_data_df)} 条日线数据，涉及 {all_data_df['ts_code'].nunique()} 只股票")
                    update_execution_progress(db, execution, message=f"已获取 {len(all_data_df)} 条数据，准备写入数据库...")

                    # 批量写入（按 ts_code 分组写入对应分表）
                    result = self.storage.upsert_daily_data_batch(db, all_data_df, extra_info, update_view=False)

                    # 批量同步完成后，统一更新一次视图
                    logger.info("批量同步完成，开始更新视图...")
                    update_execution_progress(db, execution, progress_percent=100, message="同步完成")
                    from zquant.data.view_manager import create_or_update_daily_view

                    create_or_update_daily_view(db)
                    logger.info("视图更新完成")

                    logger.info(
                        f"所有股票日线数据同步完成: 成功 {result['success']}/{result['total']}，失败 {len(result['failed'])}"
                    )

                    # 记录操作日志：如果包含 table_details，按主表名汇总后记录日志
                    end_time = datetime.now()
                    created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

                    if result.get("table_details"):
                        # 按主表名分组汇总
                        from collections import defaultdict
                        main_table_groups = defaultdict(lambda: {
                            "insert_count": 0,
                            "update_count": 0,
                            "delete_count": 0,
                            "success_count": 0,
                            "failed_count": 0,
                            "error_messages": [],
                        })

                        for table_detail in result["table_details"]:
                            table_name = table_detail.get("table_name", "")
                            if DataService.is_split_table(table_name):
                                # 是分表，按主表名分组
                                main_table_name = DataService.get_main_table_name(table_name)
                                group = main_table_groups[main_table_name]
                                group["insert_count"] += table_detail.get("count", 0)
                                group["update_count"] += table_detail.get("update_count", 0)
                                group["delete_count"] += table_detail.get("delete_count", 0)
                                if table_detail.get("success", False):
                                    group["success_count"] += 1
                                else:
                                    group["failed_count"] += 1
                                    if table_detail.get("error_message"):
                                        group["error_messages"].append(table_detail.get("error_message"))
                            else:
                                # 不是分表，直接记录
                                try:
                                    operation_result = "success" if table_detail.get("success", False) else "failed"
                                    DataService.create_data_operation_log(
                                        db=db,
                                        table_name=table_name,
                                        operation_type="sync",
                                        operation_result=operation_result,
                                        start_time=start_time,
                                        end_time=end_time,
                                        insert_count=table_detail.get("count", 0),
                                        update_count=table_detail.get("update_count", 0),
                                        delete_count=table_detail.get("delete_count", 0),
                                        error_message=table_detail.get("error_message"),
                                        created_by=created_by,
                                        data_source="tushare",
                                        api_interface="daily",
                                        api_data_count=table_detail.get("count", 0),
                                    )
                                except Exception as log_error:
                                    logger.warning(f"记录表 {table_name} 操作日志失败: {log_error}")

                        # 为每个主表记录一条汇总日志
                        for main_table_name, group in main_table_groups.items():
                            try:
                                # 确定操作结果
                                if group["failed_count"] == 0:
                                    operation_result = "success"
                                elif group["success_count"] == 0:
                                    operation_result = "failed"
                                else:
                                    operation_result = "partial_success"

                                # 汇总错误信息
                                error_message = None
                                if group["error_messages"]:
                                    # 只保留前3个错误信息，避免过长
                                    error_messages = group["error_messages"][:3]
                                    error_message = "; ".join(error_messages)
                                    if len(group["error_messages"]) > 3:
                                        error_message += f" (还有 {len(group['error_messages']) - 3} 个错误)"

                                DataService.create_data_operation_log(
                                    db=db,
                                    table_name=main_table_name,
                                    operation_type="sync",
                                    operation_result=operation_result,
                                    start_time=start_time,
                                    end_time=end_time,
                                    insert_count=group["insert_count"],
                                    update_count=group["update_count"],
                                    delete_count=group["delete_count"],
                                    error_message=error_message,
                                    created_by=created_by,
                                    data_source="tushare",
                                    api_interface="daily",
                                    api_data_count=group["insert_count"],
                                )
                            except Exception as log_error:
                                logger.warning(f"记录主表 {main_table_name} 操作日志失败: {log_error}")
                    else:
                        # 向后兼容：如果没有 table_details，记录汇总日志
                        table_name = "zq_data_tustock_daily_all"
                        operation_result = "success" if len(result.get("failed", [])) == 0 else "partial_success"
                        try:
                            DataService.create_data_operation_log(
                                db=db,
                                table_name=table_name,
                                operation_type="sync",
                                operation_result=operation_result,
                                start_time=start_time,
                                end_time=end_time,
                                insert_count=result.get("success", 0),
                                update_count=0,
                                delete_count=0,
                                error_message=f"失败: {len(result.get('failed', []))} 只股票"
                                if result.get("failed")
                                else None,
                                created_by=created_by,
                                data_source="tushare",
                                api_interface="daily",
                                api_data_count=result.get("success", 0),
                            )
                        except Exception as log_error:
                            logger.warning(f"记录操作日志失败: {log_error}")

                    return result

                except Exception as e:
                    # 记录失败的操作日志
                    end_time = datetime.now()
                    table_name = "zq_data_tustock_daily_all"
                    created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
                    try:
                        DataService.create_data_operation_log(
                            db=db,
                            table_name=table_name,
                            operation_type="sync",
                            operation_result="failed",
                            start_time=start_time,
                            end_time=end_time,
                            insert_count=0,
                            update_count=0,
                            delete_count=0,
                            error_message=str(e),
                            created_by=created_by,
                            data_source="tushare",
                            api_interface="daily",
                            api_data_count=0,
                        )
                    except Exception as log_error:
                        logger.warning(f"记录操作日志失败: {log_error}")

                    logger.error(f"批量同步日线数据失败: {e}")
                    raise
            else:
                # 按时间段同步：保持原有循环调用逻辑
                logger.info(f"按时间段同步模式：{start_date} 至 {end_date}")

                # 获取股票列表
                not_found = set()
                if codelist:
                    # 如果提供了 codelist，只同步列表中的股票
                    logger.info(f"指定股票列表，共 {len(codelist)} 只股票")
                    # 验证 codelist 中的股票是否存在，并按代码排序确保顺序稳定
                    stocks = (
                        db.query(Tustock)
                        .filter(Tustock.ts_code.in_(codelist), Tustock.delist_date.is_(None))
                        .order_by(Tustock.ts_code)
                        .all()
                    )
                    found_ts_codes = {stock.ts_code for stock in stocks}
                    not_found = set(codelist) - found_ts_codes
                    if not_found:
                        logger.warning(f"以下TS代码在数据库中未找到或已退市: {not_found}")
                else:
                    # 获取所有上市股票，并按代码排序确保顺序稳定
                    stocks = db.query(Tustock).filter(Tustock.delist_date.is_(None)).order_by(Tustock.ts_code).all()

                # 处理恢复模式
                resume_from_id = None
                if execution:
                    resume_from_id = execution.get_result().get("resume_from_execution_id")
                
                skip_until = None
                if resume_from_id:
                    old_execution = db.query(TaskExecution).filter(TaskExecution.id == resume_from_id).first()
                    if old_execution:
                        skip_until = old_execution.current_item
                        logger.info(f"[数据同步] 从执行记录 {resume_from_id} 恢复，准备跳过直到 {skip_until}")

                total = len(stocks)
                success = 0
                failed = []
                skipped_count = 0

                update_execution_progress(db, execution, total_items=total, processed_items=0, message="正在开始循环同步...")

                has_reached_resume_point = skip_until is None
                for i, stock in enumerate(stocks, 1):
                    # 如果在恢复模式下，跳过直到达到断点
                    if not has_reached_resume_point:
                        if stock.ts_code == skip_until:
                            has_reached_resume_point = True
                            logger.info(f"[数据同步] 已到达恢复点: {stock.ts_code}，将跳过该股票并从下一只开始")
                            skipped_count += 1
                            success += 1
                            continue
                        else:
                            skipped_count += 1
                            success += 1  # 视为已成功，为了进度条显示计入
                            continue

                    try:
                        # 高频检查暂停和终止请求（每一轮都检查）
                        from zquant.scheduler.utils import check_control_flags
                        check_control_flags(db, execution)

                        # 进度更新频率控制：每10个股票或首尾股票更新一次数据库
                        if i % 10 == 0 or i == total or i == skipped_count + 1:
                            update_execution_progress(
                                db, 
                                execution, 
                                processed_items=i-1,
                                total_items=total,
                                current_item=stock.ts_code,
                                message=f"正在同步日线数据: {stock.ts_code} ({i}/{total})..."
                            )
                        else:
                            # 仅更新内存，不写库，确保断点信息是最新的
                            if execution:
                                execution.current_item = stock.ts_code
                                execution.processed_items = i - 1
                        
                        # 日志记录进度
                        if i % 10 == 0 or i == total:
                            logger.info(
                                f"日线数据同步进度: {stock.ts_code} - "
                                f"已处理 {i}/{total} 个股票 "
                                f"(成功={success}, 失败={len(failed)})"
                            )
                        
                        # 批量同步时，不更新视图，减少锁竞争
                        self.sync_daily_data(db, stock.ts_code, start_date, end_date, extra_info, update_view=False)
                        success += 1
                        
                        # 批次进度日志（每100个股票）
                        if i % 100 == 0:
                            logger.info(f"日线数据同步批次进度: {i}/{total} (成功={success}, 失败={len(failed)})")
                    except Exception as e:
                        if "Task terminated" in str(e):
                            raise
                        logger.error(f"同步 {stock.ts_code} 失败: {e}")
                        failed.append(stock.ts_code)

                update_execution_progress(db, execution, processed_items=total, message="循环同步完成，正在更新视图...")

                # 如果提供了 codelist 且有未找到的股票，将它们添加到失败列表
                if not_found:
                    failed.extend(list(not_found))
                    total += len(not_found)  # 更新总数

                # 批量同步完成后，统一更新一次视图
                logger.info("批量同步完成，开始更新视图...")
                from zquant.data.view_manager import create_or_update_daily_view

                create_or_update_daily_view(db)
                logger.info("视图更新完成")

                logger.info(f"所有股票日线数据同步完成: 成功 {success}/{total}，失败 {len(failed)}")

                # 记录操作日志
                end_time = datetime.now()
                table_name = "zq_data_tustock_daily_all"
                operation_result = "success" if len(failed) == 0 else "partial_success"
                created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
                try:
                    DataService.create_data_operation_log(
                        db=db,
                        table_name=table_name,
                        operation_type="sync",
                        operation_result=operation_result,
                        start_time=start_time,
                        end_time=end_time,
                        insert_count=success,
                        update_count=0,
                        delete_count=0,
                        error_message=f"失败: {len(failed)} 只股票" if failed else None,
                        created_by=created_by,
                        data_source="tushare",
                        api_interface="daily",
                        api_data_count=success,
                    )
                except Exception as log_error:
                    logger.warning(f"记录操作日志失败: {log_error}")

                return {"total": total, "success": success, "failed": failed}
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            table_name = "zq_data_tustock_daily_all"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily",
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步所有股票日线数据失败: {e}")
            raise

    def sync_daily_basic_data(
        self,
        db: Session,
        ts_code: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        update_view: bool = True,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步单只股票的每日指标数据（按 ts_code 分表存储）

        Args:
            db: 数据库会话
            ts_code: TS代码，如：000001.SZ
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            update_view: 是否更新视图，默认True。批量同步时建议设置为False，完成后统一更新
            execution: 执行记录对象（可选）
        """
        try:
            # 确保基础表存在
            from zquant.models.data import Tustock

            self._ensure_tables_exist(db, [Tustock.__tablename__])

            logger.info(f"开始同步 {ts_code} 每日指标数据...")
            update_execution_progress(db, execution, message=f"正在同步 {ts_code} 每日指标数据...")
            
            if not start_date:
                # 默认获取最近一年的数据
                start_date = (date.today() - timedelta(days=365)).strftime("%Y%m%d")
            if not end_date:
                end_date = date.today().strftime("%Y%m%d")

            # 获取每日指标数据
            df = self.tushare.get_daily_basic_data(ts_code, start_date, end_date)
            if df.empty:
                logger.warning(f"{ts_code} 无每日指标数据")
                update_execution_progress(db, execution, message=f"{ts_code} 无每日指标数据")
                return 0

            # 记录开始时间
            start_time = datetime.now()

            # 使用新的分表存储方法
            count = self.storage.upsert_daily_basic_data(db, df, ts_code, extra_info, update_view)

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import get_daily_basic_table_name

            table_name = get_daily_basic_table_name(ts_code)
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily_basic",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"{ts_code} 每日指标数据同步完成，更新 {count} 条")
            update_execution_progress(db, execution, message=f"{ts_code} 每日指标同步完成，更新 {count} 条")
            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import get_daily_basic_table_name

            table_name = get_daily_basic_table_name(ts_code)
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily_basic",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步 {ts_code} 每日指标数据失败: {e}")
            raise

    def sync_all_daily_basic_data(
        self,
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        codelist: List[str] | None = None,
        execution: Optional[TaskExecution] = None,
    ) -> dict:
        """
        同步所有股票的每日指标数据（增量更新）

        Args:
            db: 数据库会话
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            codelist: TS代码列表（可选）
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            logger.info("开始同步所有股票每日指标数据...")
            update_execution_progress(db, execution, message="正在准备同步...")
            from zquant.models.data import Tustock

            # 确保基础表存在
            self._ensure_tables_exist(db, [Tustock.__tablename__])

            # 判断是否为按天同步（开始日期和结束日期相同）
            is_single_day = start_date and end_date and start_date == end_date

            if is_single_day:
                # 按天同步：调用一次 API 获取所有股票数据，然后批量写入
                logger.info(f"按天同步模式：{start_date}")
                update_execution_progress(db, execution, message=f"正在通过批量API获取数据: {start_date}")
                try:
                    # 调用批量 API 获取所有股票数据
                    all_data_df = self.tushare.get_all_daily_basic_data_by_date(start_date)

                    if all_data_df.empty:
                        logger.warning(f"{start_date} 无数据")
                        return {"total": 0, "success": 0, "failed": []}

                    if codelist:
                        all_data_df = all_data_df[all_data_df["ts_code"].isin(codelist)]
                        if all_data_df.empty:
                            logger.warning(f"{start_date} 在指定股票列表中无数据")
                            return {"total": len(codelist), "success": 0, "failed": codelist}

                    logger.info(
                        f"获取到 {len(all_data_df)} 条每日指标数据，涉及 {all_data_df['ts_code'].nunique()} 只股票"
                    )
                    update_execution_progress(db, execution, message=f"已获取 {len(all_data_df)} 条数据，准备写入数据库...")

                    # 批量写入（按 ts_code 分组写入对应分表）
                    result = self.storage.upsert_daily_basic_data_batch(db, all_data_df, extra_info, update_view=False)

                    # 批量同步完成后，统一更新一次视图
                    logger.info("批量同步完成，开始更新视图...")
                    update_execution_progress(db, execution, progress_percent=100, message="同步完成")
                    from zquant.data.view_manager import create_or_update_daily_basic_view

                    create_or_update_daily_basic_view(db)
                    logger.info("视图更新完成")

                    logger.info(
                        f"所有股票每日指标数据同步完成: 成功 {result['success']}/{result['total']}，失败 {len(result['failed'])}"
                    )

                    # 记录操作日志：如果包含 table_details，按主表名汇总后记录日志
                    end_time = datetime.now()
                    created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

                    if result.get("table_details"):
                        # 按主表名分组汇总
                        from collections import defaultdict
                        main_table_groups = defaultdict(lambda: {
                            "insert_count": 0,
                            "update_count": 0,
                            "delete_count": 0,
                            "success_count": 0,
                            "failed_count": 0,
                            "error_messages": [],
                        })

                        for table_detail in result["table_details"]:
                            table_name = table_detail.get("table_name", "")
                            if DataService.is_split_table(table_name):
                                # 是分表，按主表名分组
                                main_table_name = DataService.get_main_table_name(table_name)
                                group = main_table_groups[main_table_name]
                                group["insert_count"] += table_detail.get("count", 0)
                                group["update_count"] += table_detail.get("update_count", 0)
                                group["delete_count"] += table_detail.get("delete_count", 0)
                                if table_detail.get("success", False):
                                    group["success_count"] += 1
                                else:
                                    group["failed_count"] += 1
                                    if table_detail.get("error_message"):
                                        group["error_messages"].append(table_detail.get("error_message"))
                            else:
                                # 不是分表，直接记录
                                try:
                                    operation_result = "success" if table_detail.get("success", False) else "failed"
                                    DataService.create_data_operation_log(
                                        db=db,
                                        table_name=table_name,
                                        operation_type="sync",
                                        operation_result=operation_result,
                                        start_time=start_time,
                                        end_time=end_time,
                                        insert_count=table_detail.get("count", 0),
                                        update_count=table_detail.get("update_count", 0),
                                        delete_count=table_detail.get("delete_count", 0),
                                        error_message=table_detail.get("error_message"),
                                        created_by=created_by,
                                        data_source="tushare",
                                        api_interface="daily_basic",
                                        api_data_count=table_detail.get("count", 0),
                                    )
                                except Exception as log_error:
                                    logger.warning(f"记录表 {table_name} 操作日志失败: {log_error}")

                        # 为每个主表记录一条汇总日志
                        for main_table_name, group in main_table_groups.items():
                            try:
                                # 确定操作结果
                                if group["failed_count"] == 0:
                                    operation_result = "success"
                                elif group["success_count"] == 0:
                                    operation_result = "failed"
                                else:
                                    operation_result = "partial_success"

                                # 汇总错误信息
                                error_message = None
                                if group["error_messages"]:
                                    # 只保留前3个错误信息，避免过长
                                    error_messages = group["error_messages"][:3]
                                    error_message = "; ".join(error_messages)
                                    if len(group["error_messages"]) > 3:
                                        error_message += f" (还有 {len(group['error_messages']) - 3} 个错误)"

                                DataService.create_data_operation_log(
                                    db=db,
                                    table_name=main_table_name,
                                    operation_type="sync",
                                    operation_result=operation_result,
                                    start_time=start_time,
                                    end_time=end_time,
                                    insert_count=group["insert_count"],
                                    update_count=group["update_count"],
                                    delete_count=group["delete_count"],
                                    error_message=error_message,
                                    created_by=created_by,
                                    data_source="tushare",
                                    api_interface="daily_basic",
                                    api_data_count=group["insert_count"],
                                )
                            except Exception as log_error:
                                logger.warning(f"记录主表 {main_table_name} 操作日志失败: {log_error}")
                    else:
                        # 向后兼容：如果没有 table_details，记录汇总日志
                        table_name = "zq_data_tustock_daily_basic_all"
                        operation_result = "success" if len(result.get("failed", [])) == 0 else "partial_success"
                        try:
                            DataService.create_data_operation_log(
                                db=db,
                                table_name=table_name,
                                operation_type="sync",
                                operation_result=operation_result,
                                start_time=start_time,
                                end_time=end_time,
                                insert_count=result.get("success", 0),
                                update_count=0,
                                delete_count=0,
                                error_message=f"失败: {len(result.get('failed', []))} 只股票"
                                if result.get("failed")
                                else None,
                                created_by=created_by,
                                data_source="tushare",
                                api_interface="daily_basic",
                                api_data_count=result.get("success", 0),
                            )
                        except Exception as log_error:
                            logger.warning(f"记录操作日志失败: {log_error}")

                    return result

                except Exception as e:
                    # 记录失败的操作日志
                    end_time = datetime.now()
                    table_name = "zq_data_tustock_daily_basic_all"
                    created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
                    try:
                        DataService.create_data_operation_log(
                            db=db,
                            table_name=table_name,
                            operation_type="sync",
                            operation_result="failed",
                            start_time=start_time,
                            end_time=end_time,
                            insert_count=0,
                            update_count=0,
                            delete_count=0,
                            error_message=str(e),
                            created_by=created_by,
                            data_source="tushare",
                            api_interface="daily_basic",
                            api_data_count=0,
                        )
                    except Exception as log_error:
                        logger.warning(f"记录操作日志失败: {log_error}")

                    logger.error(f"批量同步每日指标数据失败: {e}")
                    raise
            else:
                # 按时间段同步：保持原有循环调用逻辑
                logger.info(f"按时间段同步模式：{start_date} 至 {end_date}")

                # 获取股票列表
                if codelist:
                    # 验证并按代码排序确保顺序稳定
                    stocks = (
                        db.query(Tustock)
                        .filter(Tustock.ts_code.in_(codelist), Tustock.delist_date.is_(None))
                        .order_by(Tustock.ts_code)
                        .all()
                    )
                else:
                    # 按代码排序确保顺序稳定
                    stocks = db.query(Tustock).filter(Tustock.delist_date.is_(None)).order_by(Tustock.ts_code).all()
                
                # 处理恢复模式
                resume_from_id = None
                if execution:
                    resume_from_id = execution.get_result().get("resume_from_execution_id")
                
                skip_until = None
                if resume_from_id:
                    old_execution = db.query(TaskExecution).filter(TaskExecution.id == resume_from_id).first()
                    if old_execution:
                        skip_until = old_execution.current_item
                        logger.info(f"[每日指标] 从执行记录 {resume_from_id} 恢复，准备跳过直到 {skip_until}")

                total = len(stocks)
                success = 0
                failed = []
                skipped_count = 0

                update_execution_progress(db, execution, total_items=total, processed_items=0, message="正在开始循环同步...")

                has_reached_resume_point = skip_until is None
                for i, stock in enumerate(stocks, 1):
                    # 如果在恢复模式下，跳过直到达到断点
                    if not has_reached_resume_point:
                        if stock.ts_code == skip_until:
                            has_reached_resume_point = True
                            logger.info(f"[每日指标] 已到达恢复点: {stock.ts_code}，将跳过该股票并从下一只开始")
                            skipped_count += 1
                            success += 1
                            continue
                        else:
                            skipped_count += 1
                            success += 1
                            continue

                    try:
                        # 高频检查暂停和终止请求（每一轮都检查）
                        from zquant.scheduler.utils import check_control_flags
                        check_control_flags(db, execution)

                        # 进度更新频率控制
                        if i % 10 == 0 or i == total or i == skipped_count + 1:
                            update_execution_progress(
                                db,
                                execution,
                                processed_items=i - 1,
                                total_items=total,
                                current_item=stock.ts_code,
                                message=f"正在同步每日指标: {stock.ts_code} ({i}/{total})...",
                            )
                        else:
                            if execution:
                                execution.current_item = stock.ts_code
                                execution.processed_items = i - 1
                        
                        # 日志记录进度
                        if i % 10 == 0 or i == total:
                            logger.info(
                                f"每日指标同步进度: {stock.ts_code} - "
                                f"已处理 {i}/{total} 个股票 "
                                f"(成功={success}, 失败={len(failed)})"
                            )
                        
                        # 批量同步时，不更新视图，减少锁竞争
                        self.sync_daily_basic_data(
                            db, stock.ts_code, start_date, end_date, extra_info, update_view=False
                        )
                        success += 1
                        
                        # 批次进度日志（每100个股票）
                        if i % 100 == 0:
                            logger.info(f"每日指标同步批次进度: {i}/{total} (成功={success}, 失败={len(failed)})")
                    except Exception as e:
                        if "Task terminated" in str(e):
                            raise
                        logger.error(f"同步 {stock.ts_code} 失败: {e}")
                        failed.append(stock.ts_code)

                update_execution_progress(db, execution, processed_items=total, message="循环同步完成，正在更新视图...")

                # 批量同步完成后，统一更新一次视图
                logger.info("批量同步完成，开始更新视图...")
                from zquant.data.view_manager import create_or_update_daily_basic_view

                create_or_update_daily_basic_view(db)
                logger.info("视图更新完成")

                logger.info(f"所有股票每日指标数据同步完成: 成功 {success}/{total}，失败 {len(failed)}")

                # 记录操作日志
                end_time = datetime.now()
                table_name = "zq_data_tustock_daily_basic_all"
                operation_result = "success" if len(failed) == 0 else "partial_success"
                created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
                try:
                    DataService.create_data_operation_log(
                        db=db,
                        table_name=table_name,
                        operation_type="sync",
                        operation_result=operation_result,
                        start_time=start_time,
                        end_time=end_time,
                        insert_count=success,
                        update_count=0,
                        delete_count=0,
                        error_message=f"失败: {len(failed)} 只股票" if failed else None,
                        created_by=created_by,
                        data_source="tushare",
                        api_interface="daily_basic",
                        api_data_count=success,
                    )
                except Exception as log_error:
                    logger.warning(f"记录操作日志失败: {log_error}")

                return {"total": total, "success": success, "failed": failed}
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            table_name = "zq_data_tustock_daily_basic_all"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="daily_basic",
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步所有股票每日指标数据失败: {e}")
            raise

    def sync_factor_data(
        self,
        db: Session,
        ts_code: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        update_view: bool = True,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步单只股票的因子数据（按 ts_code 分表存储）

        Args:
            db: 数据库会话
            ts_code: TS代码，如：000001.SZ
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            update_view: 是否更新视图，默认True。批量同步时建议设置为False，完成后统一更新
            execution: 执行记录对象（可选）
        """
        try:
            # 确保基础表存在
            from zquant.models.data import Tustock

            self._ensure_tables_exist(db, [Tustock.__tablename__])

            logger.info(f"开始同步 {ts_code} 因子数据...")
            update_execution_progress(db, execution, message=f"正在同步 {ts_code} 因子数据...")
            
            if not start_date:
                # 默认获取最后一个交易日的数据
                latest_trading_date = self._get_latest_trading_date(db)
                start_date = latest_trading_date.strftime("%Y%m%d")
            if not end_date:
                # 默认使用最后一个交易日
                latest_trading_date = self._get_latest_trading_date(db)
                end_date = latest_trading_date.strftime("%Y%m%d")

            # 记录日期范围
            logger.info(f"调用 Tushare API 获取 {ts_code} 因子数据，日期范围: {start_date} 至 {end_date}")

            # 获取因子数据
            df = self.tushare.get_stk_factor(ts_code, start_date, end_date)
            
            # 记录获取到的数据信息
            if df.empty:
                logger.warning(
                    f"{ts_code} 无因子数据 - 日期范围: {start_date} 至 {end_date}, "
                    f"可能原因: 1) 该日期范围内确实无数据 2) API 返回空 3) 日期格式问题"
                )
                update_execution_progress(db, execution, message=f"{ts_code} 无因子数据")
                return 0
            
            # 记录数据基本信息
            data_count = len(df)
            date_range_info = ""
            if "trade_date" in df.columns and not df.empty:
                min_date = df["trade_date"].min()
                max_date = df["trade_date"].max()
                date_range_info = f", 数据日期范围: {min_date} 至 {max_date}"
            
            logger.info(
                f"从 Tushare API 获取到 {ts_code} 因子数据: {data_count} 条记录"
                f"{date_range_info}, 列数: {len(df.columns)}"
            )
            
            # 记录开始时间
            start_time = datetime.now()

            # 记录即将存储的数据
            logger.info(f"准备存储 {ts_code} 因子数据到数据库，共 {data_count} 条记录")

            # 使用新的分表存储方法
            count = self.storage.upsert_factor_data(db, df, ts_code, extra_info, update_view)
            
            # 记录存储结果
            if count != data_count:
                logger.warning(
                    f"{ts_code} 因子数据存储结果不一致: 获取 {data_count} 条，实际存储 {count} 条"
                )

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import get_factor_table_name

            table_name = get_factor_table_name(ts_code)
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"{ts_code} 因子数据同步完成，更新 {count} 条")
            update_execution_progress(db, execution, message=f"{ts_code} 因子数据同步完成，更新 {count} 条")
            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import get_factor_table_name

            table_name = get_factor_table_name(ts_code)
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步 {ts_code} 因子数据失败: {e}")
            raise

    def sync_all_factor_data(
        self,
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        codelist: List[str] | None = None,
        execution: Optional[TaskExecution] = None,
    ) -> dict:
        """
        同步所有股票的因子数据

        Args:
            db: 数据库会话
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            codelist: TS代码列表（可选）
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            logger.info("开始同步所有股票因子数据...")
            update_execution_progress(db, execution, message="正在准备同步...")
            from zquant.models.data import Tustock

            # 确保基础表存在
            self._ensure_tables_exist(db, [Tustock.__tablename__])

            # 获取所有股票列表
            if codelist:
                # 验证并按代码排序确保顺序稳定
                stocks = (
                    db.query(Tustock)
                    .filter(Tustock.ts_code.in_(codelist), Tustock.delist_date.is_(None))
                    .order_by(Tustock.ts_code)
                    .all()
                )
            else:
                # 按代码排序确保顺序稳定
                stocks = db.query(Tustock).filter(Tustock.delist_date.is_(None)).order_by(Tustock.ts_code).all()
            
            # 处理恢复模式
            resume_from_id = None
            if execution:
                resume_from_id = execution.get_result().get("resumed_from")
            
            skip_until = None
            if resume_from_id:
                old_execution = db.query(TaskExecution).filter(TaskExecution.id == resume_from_id).first()
                if old_execution:
                    skip_until = old_execution.current_item
                    logger.info(f"[技术因子] 从执行记录 {resume_from_id} 恢复，准备跳过直到 {skip_until}")

            total = len(stocks)
            logger.info(f"共 {total} 只股票需要同步因子数据")

            success = 0
            failed = []
            skipped_count = 0

            update_execution_progress(db, execution, total_items=total, processed_items=0, message="正在开始循环同步...")

            has_reached_resume_point = skip_until is None
            for i, stock in enumerate(stocks, 1):
                # 如果在恢复模式下，跳过直到达到断点
                if not has_reached_resume_point:
                    if stock.ts_code == skip_until:
                        has_reached_resume_point = True
                        logger.info(f"[技术因子] 已到达恢复点: {stock.ts_code}，将跳过该股票并从下一只开始")
                        skipped_count += 1
                        success += 1
                        continue
                    else:
                        skipped_count += 1
                        success += 1
                        continue

                try:
                    # 高频检查暂停和终止请求
                    from zquant.scheduler.utils import check_control_flags
                    check_control_flags(db, execution)

                    # 进度更新频率控制
                    if i % 10 == 0 or i == total or i == skipped_count + 1:
                        update_execution_progress(
                            db,
                            execution,
                            processed_items=i - 1,
                            total_items=total,
                            current_item=stock.ts_code,
                            message=f"正在同步技术因子: {stock.ts_code} ({i}/{total})...",
                        )
                    else:
                        if execution:
                            execution.current_item = stock.ts_code
                            execution.processed_items = i - 1
                    
                    # 日志记录进度
                    if i % 10 == 0 or i == total:
                        logger.info(
                            f"技术因子同步进度: {stock.ts_code} - "
                            f"已处理 {i}/{total} 个股票 "
                            f"(成功={success}, 失败={len(failed)})"
                        )
                    
                    self.sync_factor_data(db, stock.ts_code, start_date, end_date, extra_info, update_view=False)
                    success += 1
                    
                    # 批次进度日志（每100个股票）
                    if i % 100 == 0:
                        logger.info(f"技术因子同步批次进度: {i}/{total} (成功={success}, 失败={len(failed)})")
                except Exception as e:
                    if "Task terminated" in str(e):
                        raise
                    logger.error(f"同步 {stock.ts_code} 因子数据失败: {e}")
                    failed.append(stock.ts_code)

            update_execution_progress(db, execution, processed_items=total, message="循环同步完成，正在更新视图...")

            # 批量同步完成后，统一更新一次视图
            logger.info("批量同步完成，开始更新视图...")
            from zquant.data.view_manager import create_or_update_factor_view

            create_or_update_factor_view(db)
            logger.info("视图更新完成")

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import TUSTOCK_FACTOR_VIEW_NAME
            table_name = TUSTOCK_FACTOR_VIEW_NAME
            operation_result = "success" if len(failed) == 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=success,
                    update_count=0,
                    delete_count=0,
                    error_message=f"失败: {len(failed)} 只股票" if failed else None,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor",
                    api_data_count=success,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"所有股票因子数据同步完成: 成功 {success}/{total}, 失败 {len(failed)}")
            return {"total": total, "success": success, "failed": failed}
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import TUSTOCK_FACTOR_VIEW_NAME
            table_name = TUSTOCK_FACTOR_VIEW_NAME
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor",
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步所有股票因子数据失败: {e}")
            raise

    def sync_stkfactorpro_data(
        self,
        db: Session,
        ts_code: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        update_view: bool = True,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步单只股票的专业版因子数据（按 ts_code 分表存储）

        Args:
            db: 数据库会话
            ts_code: TS代码，如：000001.SZ
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            update_view: 是否更新视图，默认True。批量同步时建议设置为False，完成后统一更新
            execution: 执行记录对象（可选）
        """
        try:
            # 确保基础表存在
            from zquant.models.data import Tustock

            self._ensure_tables_exist(db, [Tustock.__tablename__])

            logger.info(f"开始同步 {ts_code} 专业版因子数据...")
            update_execution_progress(db, execution, message=f"正在同步 {ts_code} 专业版因子数据...")
            
            if not start_date:
                # 默认获取最后一个交易日的数据
                latest_trading_date = self._get_latest_trading_date(db)
                start_date = latest_trading_date.strftime("%Y%m%d")
            if not end_date:
                # 默认使用最后一个交易日
                latest_trading_date = self._get_latest_trading_date(db)
                end_date = latest_trading_date.strftime("%Y%m%d")

            # 记录日期范围
            logger.info(f"调用 Tushare API 获取 {ts_code} 专业版因子数据，日期范围: {start_date} 至 {end_date}")

            # 获取专业版因子数据
            df = self.tushare.get_stk_factor_pro(ts_code, start_date, end_date)
            
            # 记录获取到的数据信息
            if df.empty:
                logger.warning(
                    f"{ts_code} 无专业版因子数据 - 日期范围: {start_date} 至 {end_date}, "
                    f"可能原因: 1) 该日期范围内确实无数据 2) API 返回空 3) 日期格式问题"
                )
                update_execution_progress(db, execution, message=f"{ts_code} 无专业版因子数据")
                return 0
            
            # 记录数据基本信息
            data_count = len(df)
            date_range_info = ""
            if "trade_date" in df.columns and not df.empty:
                min_date = df["trade_date"].min()
                max_date = df["trade_date"].max()
                date_range_info = f", 数据日期范围: {min_date} 至 {max_date}"
            
            logger.info(
                f"从 Tushare API 获取到 {ts_code} 专业版因子数据: {data_count} 条记录"
                f"{date_range_info}, 列数: {len(df.columns)}"
            )
            
            # 记录开始时间
            start_time = datetime.now()

            # 记录即将存储的数据
            logger.info(f"准备存储 {ts_code} 专业版因子数据到数据库，共 {data_count} 条记录")

            # 使用新的分表存储方法
            count = self.storage.upsert_stkfactorpro_data(db, df, ts_code, extra_info, update_view)
            
            # 记录存储结果
            if count != data_count:
                logger.warning(
                    f"{ts_code} 专业版因子数据存储结果不一致: 获取 {data_count} 条，实际存储 {count} 条"
                )

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import get_stkfactorpro_table_name

            table_name = get_stkfactorpro_table_name(ts_code)
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor_pro",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"{ts_code} 专业版因子数据同步完成，更新 {count} 条")
            update_execution_progress(db, execution, message=f"{ts_code} 专业版因子同步完成，更新 {count} 条")
            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import get_stkfactorpro_table_name

            table_name = get_stkfactorpro_table_name(ts_code)
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time if "start_time" in locals() else datetime.now(),
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor_pro",
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步 {ts_code} 专业版因子数据失败: {e}")
            raise

    def sync_all_stkfactorpro_data(
        self,
        db: Session,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        codelist: List[str] | None = None,
        execution: Optional[TaskExecution] = None,
    ) -> dict:
        """
        同步所有股票的专业版因子数据

        Args:
            db: 数据库会话
            start_date: 开始日期，格式：YYYYMMDD
            end_date: 结束日期，格式：YYYYMMDD
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            codelist: TS代码列表（可选）
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            logger.info("开始同步所有股票专业版因子数据...")
            update_execution_progress(db, execution, message="正在准备同步...")
            from zquant.models.data import Tustock

            # 确保基础表存在
            self._ensure_tables_exist(db, [Tustock.__tablename__])

            # 获取所有股票列表
            if codelist:
                # 验证并按代码排序确保顺序稳定
                stocks = (
                    db.query(Tustock)
                    .filter(Tustock.ts_code.in_(codelist), Tustock.delist_date.is_(None))
                    .order_by(Tustock.ts_code)
                    .all()
                )
            else:
                # 按代码排序确保顺序稳定
                stocks = db.query(Tustock).filter(Tustock.delist_date.is_(None)).order_by(Tustock.ts_code).all()
            
            # 处理恢复模式
            resume_from_id = None
            if execution:
                resume_from_id = execution.get_result().get("resume_from_execution_id")
            
            skip_until = None
            if resume_from_id:
                old_execution = db.query(TaskExecution).filter(TaskExecution.id == resume_from_id).first()
                if old_execution:
                    skip_until = old_execution.current_item
                    logger.info(f"[专业版因子] 从执行记录 {resume_from_id} 恢复，准备跳过直到 {skip_until}")

            total = len(stocks)
            logger.info(f"共 {total} 只股票需要同步专业版因子数据")

            success = 0
            failed = []
            skipped_count = 0

            update_execution_progress(db, execution, total_items=total, processed_items=0, message="正在开始循环同步...")

            has_reached_resume_point = skip_until is None
            for i, stock in enumerate(stocks, 1):
                # 如果在恢复模式下，跳过直到达到断点
                if not has_reached_resume_point:
                    if stock.ts_code == skip_until:
                        has_reached_resume_point = True
                        logger.info(f"[专业版因子] 已到达恢复点: {stock.ts_code}，将跳过该股票并从下一只开始")
                        skipped_count += 1
                        success += 1
                        continue
                    else:
                        skipped_count += 1
                        success += 1
                        continue

                try:
                    # 高频检查暂停和终止请求
                    from zquant.scheduler.utils import check_control_flags
                    check_control_flags(db, execution)

                    # 进度更新频率控制
                    if i % 10 == 0 or i == total or i == skipped_count + 1:
                        update_execution_progress(
                            db,
                            execution,
                            processed_items=i - 1,
                            total_items=total,
                            current_item=stock.ts_code,
                            message=f"正在同步专业版因子: {stock.ts_code} ({i}/{total})...",
                        )
                    else:
                        if execution:
                            execution.current_item = stock.ts_code
                            execution.processed_items = i - 1
                    
                    # 日志记录进度
                    if i % 10 == 0 or i == total:
                        logger.info(
                            f"专业版因子同步进度: {stock.ts_code} - "
                            f"已处理 {i}/{total} 个股票 "
                            f"(成功={success}, 失败={len(failed)})"
                        )
                    
                    self.sync_stkfactorpro_data(db, stock.ts_code, start_date, end_date, extra_info, update_view=False)
                    success += 1
                    
                    # 批次进度日志（每100个股票）
                    if i % 100 == 0:
                        logger.info(f"专业版因子同步批次进度: {i}/{total} (成功={success}, 失败={len(failed)})")
                except Exception as e:
                    if "Task terminated" in str(e):
                        raise
                    logger.error(f"同步 {stock.ts_code} 专业版因子数据失败: {e}")
                    failed.append(stock.ts_code)

            update_execution_progress(db, execution, processed_items=total, message="循环同步完成，正在更新视图...")

            # 批量同步完成后，统一更新一次视图
            logger.info("批量同步完成，开始更新视图...")
            from zquant.data.view_manager import create_or_update_stkfactorpro_view

            create_or_update_stkfactorpro_view(db)
            logger.info("视图更新完成")

            # 记录结束时间和结果
            end_time = datetime.now()
            from zquant.models.data import TUSTOCK_STKFACTORPRO_VIEW_NAME
            table_name = TUSTOCK_STKFACTORPRO_VIEW_NAME
            operation_result = "success" if len(failed) == 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=success,
                    update_count=0,
                    delete_count=0,
                    error_message=f"失败: {len(failed)} 只股票" if failed else None,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor_pro",
                    api_data_count=success,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"所有股票专业版因子数据同步完成: 成功 {success}/{total}, 失败 {len(failed)}")
            return {"total": total, "success": success, "failed": failed}
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import TUSTOCK_STKFACTORPRO_VIEW_NAME
            table_name = TUSTOCK_STKFACTORPRO_VIEW_NAME
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface="stk_factor_pro",
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步所有股票专业版因子数据失败: {e}")
            raise

    def sync_financial_data(
        self,
        db: Session,
        symbol: str,
        statement_type: str = "income",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        execution: Optional[TaskExecution] = None,
    ) -> int:
        """
        同步单只股票的财务数据

        Args:
            db: 数据库会话
            symbol: 股票代码
            statement_type: 报表类型
            start_date: 开始日期
            end_date: 结束日期
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            # 确保表存在
            from zquant.models.data import Fundamental, Tustock

            self._ensure_tables_exist(db, [Fundamental.__tablename__, Tustock.__tablename__])

            logger.info(f"开始同步 {symbol} 财务数据（{statement_type}）...")
            update_execution_progress(db, execution, message=f"正在同步 {symbol} 财务数据（{statement_type}）...")
            
            if statement_type not in ["income", "balance", "cashflow"]:
                raise ValueError(f"不支持的报表类型: {statement_type}")

            df = self.tushare.get_fundamentals(
                symbol, start_date=start_date or "", end_date=end_date or "", statement_type=statement_type
            )
            if df.empty:
                logger.warning(f"{symbol} 无财务数据（{statement_type}）")
                update_execution_progress(db, execution, message=f"{symbol} 无财务数据（{statement_type}）")
                return 0

            count = self.storage.upsert_fundamentals(db, df, symbol, statement_type, extra_info)

            # 记录结束时间和结果
            end_time = datetime.now()
            table_name = Fundamental.__tablename__
            operation_result = "success" if count > 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=count,
                    update_count=0,
                    delete_count=0,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface=statement_type,
                    api_data_count=len(df) if "df" in locals() else 0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"{symbol} 财务数据（{statement_type}）同步完成，更新 {count} 条")
            update_execution_progress(db, execution, message=f"{symbol} 财务数据（{statement_type}）同步完成，更新 {count} 条")
            return count
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import Fundamental

            table_name = Fundamental.__tablename__
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface=statement_type,
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步 {symbol} 财务数据（{statement_type}）失败: {e}")
            raise

    def sync_all_financial_data(
        self,
        db: Session,
        statement_type: str = "income",
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        extra_info: Optional[dict] = None,
        codelist: List[str] | None = None,
        execution: Optional[TaskExecution] = None,
    ) -> dict:
        """
        同步所有股票的财务数据（增量更新）

        Args:
            db: 数据库会话
            statement_type: 报表类型
            start_date: 开始日期
            end_date: 结束日期
            extra_info: 额外信息字典，可包含 created_by 和 updated_by 字段
            codelist: TS代码列表（可选）
            execution: 执行记录对象（可选）
        """
        start_time = datetime.now()
        try:
            logger.info(f"开始同步所有股票财务数据（{statement_type}）...")
            update_execution_progress(db, execution, message=f"正在同步所有股票财务数据（{statement_type}）...")
            from zquant.models.data import Fundamental, Tustock

            # 获取所有上市股票
            if codelist:
                # 验证并按代码排序确保顺序稳定
                stocks = (
                    db.query(Tustock)
                    .filter(Tustock.ts_code.in_(codelist), Tustock.delist_date.is_(None))
                    .order_by(Tustock.ts_code)
                    .all()
                )
            else:
                # 按代码排序确保顺序稳定
                stocks = db.query(Tustock).filter(Tustock.delist_date.is_(None)).order_by(Tustock.ts_code).all()
            
            # 处理恢复模式
            resume_from_id = None
            if execution:
                resume_from_id = execution.get_result().get("resumed_from")
            
            skip_until = None
            if resume_from_id:
                old_execution = db.query(TaskExecution).filter(TaskExecution.id == resume_from_id).first()
                if old_execution:
                    skip_until = old_execution.current_item
                    logger.info(f"[财务数据] 从执行记录 {resume_from_id} 恢复，准备跳过直到 {skip_until}")

            total = len(stocks)
            success = 0
            failed = []
            skipped_count = 0

            update_execution_progress(db, execution, total_items=total, processed_items=0, message="正在开始循环同步...")

            has_reached_resume_point = skip_until is None
            for i, stock in enumerate(stocks, 1):
                # 如果在恢复模式下，跳过直到达到断点
                if not has_reached_resume_point:
                    if stock.ts_code == skip_until:
                        has_reached_resume_point = True
                        logger.info(f"[财务数据] 已到达恢复点: {stock.ts_code}，将跳过该股票并从下一只开始")
                        skipped_count += 1
                        success += 1
                        continue
                    else:
                        skipped_count += 1
                        success += 1
                        continue

                try:
                    # 高频检查暂停和终止请求
                    from zquant.scheduler.utils import check_control_flags
                    check_control_flags(db, execution)

                    # 进度更新频率控制
                    if i % 10 == 0 or i == total or i == skipped_count + 1:
                        update_execution_progress(
                            db,
                            execution,
                            processed_items=i - 1,
                            total_items=total,
                            current_item=stock.ts_code,
                            message=f"正在同步财务数据: {stock.ts_code} ({i}/{total})...",
                        )
                    else:
                        if execution:
                            execution.current_item = stock.ts_code
                            execution.processed_items = i - 1
                    
                    # 日志记录进度
                    if i % 10 == 0 or i == total:
                        logger.info(
                            f"财务数据同步进度: {stock.ts_code} ({statement_type}) - "
                            f"已处理 {i}/{total} 个股票 "
                            f"(成功={success}, 失败={len(failed)})"
                        )
                    
                    self.sync_financial_data(db, stock.ts_code, statement_type, start_date, end_date, extra_info)
                    success += 1
                    
                    # 批次进度日志（每100个股票）
                    if i % 100 == 0:
                        logger.info(f"财务数据同步批次进度: {i}/{total} (成功={success}, 失败={len(failed)})")
                except Exception as e:
                    if "Task terminated" in str(e):
                        raise
                    logger.error(f"同步 {stock.ts_code} 财务数据失败: {e}")
                    failed.append(stock.ts_code)

            update_execution_progress(db, execution, processed_items=total, message="同步完成")

            # 记录结束时间和结果
            end_time = datetime.now()
            table_name = Fundamental.__tablename__
            operation_result = "success" if len(failed) == 0 else "partial_success"
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"

            # 创建操作日志
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result=operation_result,
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=success,
                    update_count=0,
                    delete_count=0,
                    error_message=f"失败: {len(failed)} 只股票" if failed else None,
                    created_by=created_by,
                    data_source="tushare",
                    api_interface=statement_type,
                    api_data_count=success,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.info(f"所有股票财务数据（{statement_type}）同步完成: 成功 {success}/{total}, 失败 {len(failed)}")
            return {"total": total, "success": success, "failed": failed}
        except Exception as e:
            # 记录失败的操作日志
            end_time = datetime.now()
            from zquant.models.data import Fundamental

            table_name = Fundamental.__tablename__
            created_by = extra_info.get("created_by", "scheduler") if extra_info else "scheduler"
            try:
                DataService.create_data_operation_log(
                    db=db,
                    table_name=table_name,
                    operation_type="sync",
                    operation_result="failed",
                    start_time=start_time,
                    end_time=end_time,
                    insert_count=0,
                    update_count=0,
                    delete_count=0,
                    error_message=str(e),
                    created_by=created_by,
                    data_source="tushare",
                    api_interface=statement_type,
                    api_data_count=0,
                )
            except Exception as log_error:
                logger.warning(f"记录操作日志失败: {log_error}")

            logger.error(f"同步所有股票财务数据（{statement_type}）失败: {e}")
            raise
